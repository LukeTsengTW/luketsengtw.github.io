<!DOCTYPE html><html lang="zh-TW" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>【Python 網路爬蟲筆記】BeautifulSoup Library - part 3 | Yaoの程式小窩</title><meta name="author" content="LukeTseng"><meta name="copyright" content="LukeTseng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="【Python 網路爬蟲筆記】BeautifulSoup Library - part 3感謝你點進本篇文章！！我是 LukeTseng，一個熱愛資訊的無名創作者，由於近期大學開設大數據分析程式設計這門課程，裡面談到了爬蟲概念，讓我激起一些興趣，因而製作本系列筆記。 聲明：本篇筆記僅供個人學習用途，斟酌參考。 另外本篇筆記使用 VSCode 環境進行編寫，部分模組（函式庫）需自行下載。 安裝 Be"><meta property="og:type" content="article"><meta property="og:title" content="【Python 網路爬蟲筆記】BeautifulSoup Library - part 3"><meta property="og:url" content="https://luketsengtw.github.io/posts/37c25d58"><meta property="og:site_name" content="Yaoの程式小窩"><meta property="og:description" content="【Python 網路爬蟲筆記】BeautifulSoup Library - part 3感謝你點進本篇文章！！我是 LukeTseng，一個熱愛資訊的無名創作者，由於近期大學開設大數據分析程式設計這門課程，裡面談到了爬蟲概念，讓我激起一些興趣，因而製作本系列筆記。 聲明：本篇筆記僅供個人學習用途，斟酌參考。 另外本篇筆記使用 VSCode 環境進行編寫，部分模組（函式庫）需自行下載。 安裝 Be"><meta property="og:locale" content="zh_TW"><meta property="og:image" content="https://luketsengtw.github.io/img/python_cover.png"><meta property="article:published_time" content="2025-09-29T15:50:27.000Z"><meta property="article:modified_time" content="2025-09-29T15:51:03.004Z"><meta property="article:author" content="LukeTseng"><meta property="article:tag" content="Python"><meta property="article:tag" content="程式設計"><meta property="article:tag" content="python"><meta property="article:tag" content="網頁"><meta property="article:tag" content="網頁程式設計"><meta property="article:tag" content="爬蟲"><meta property="article:tag" content="web crawler"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://luketsengtw.github.io/img/python_cover.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "【Python 網路爬蟲筆記】BeautifulSoup Library - part 3",
  "url": "https://luketsengtw.github.io/posts/37c25d58",
  "image": "https://luketsengtw.github.io/img/python_cover.png",
  "datePublished": "2025-09-29T15:50:27.000Z",
  "dateModified": "2025-09-29T15:51:03.004Z",
  "author": [
    {
      "@type": "Person",
      "name": "LukeTseng",
      "url": "https://luketsengtw.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/website_favicon.ico"><link rel="canonical" href="https://luketsengtw.github.io/posts/37c25d58"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="google-site-verification" content="S50ZW5JR-4iAagicR6omYnAz8LUv5ZcouskPpuBaFBs"><link rel="manifest" href="/img/pwa/manifest.json"><link rel="apple-touch-icon" sizes="180x180" href="/img/pwa/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/pwa/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/pwa/16.png"><link rel="mask-icon" href="/img/pwa/safari-pinned-tab.svg" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>(()=>{const e={set:(e,t,o)=>{if(!o)return;const a=Date.now()+864e5*o;localStorage.setItem(e,JSON.stringify({value:t,expiry:a}))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const{value:o,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return o;localStorage.removeItem(e)}};window.btf={saveToLocal:e,getScript:(e,t={})=>new Promise((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,Object.entries(t).forEach(([e,t])=>n.setAttribute(e,t)),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),getCSS:(e,t)=>new Promise((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onload=n.onreadystatechange=()=>{n.readyState&&!/loaded|complete/.test(n.readyState)||o()},n.onerror=a,document.head.appendChild(n)}),addGlobalFn:(e,t,o=!1,a=window)=>{if(e.startsWith("pjax"))return;const n=a.globalFn||{};n[e]=n[e]||{},n[e][o||Object.keys(n[e]).length]=t,a.globalFn=n}};const t=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},o=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};btf.activateDarkMode=t,btf.activateLightMode=o;const a=e.get("theme");"dark"===a?t():"light"===a&&o();const n=e.get("aside-status");void 0!==n&&document.documentElement.classList.toggle("hide-aside","hide"===n);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-7EES35MTFS"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-7EES35MTFS"),btf.addGlobalFn("pjaxComplete",()=>{gtag("config","G-7EES35MTFS",{page_path:window.location.pathname})},"google_analytics")</script><script>!function(e,t,a,n,o){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-5BKRW8SL",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer"),btf.addGlobalFn("pjaxComplete",()=>{dataLayer.push({event:"pjaxComplete",page_title:document.title,page_location:location.href,page_path:window.location.pathname})},"google_tag_manager")</script><script>const GLOBAL_CONFIG={root:"/",algolia:{appId:"EF32H7JNEE",apiKey:"876fdde0317458bcae93bc0ded1d7176",indexName:"hexo",hitsPerPage:10,languages:{input_placeholder:"想找些什麼呢...?",hits_empty:"找不到符合您查詢的內容：${query}",hits_stats:"找到 ${hits} 筆結果，耗時 ${time} 毫秒"}},localSearch:void 0,translate:{defaultEncoding:1,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"簡"},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!0,highlightMacStyle:!0},copy:{success:"複製成功",error:"複製失敗",noSupport:"瀏覽器不支援"},relativeDate:{homepage:!1,post:!1},runtime:"",dateSuffix:{just:"剛剛",min:"分鐘前",hour:"小時前",day:"天前",month:"個月前"},copyright:void 0,lightbox:"fancybox",Snackbar:{chs_to_cht:"已切換為繁體中文",cht_to_chs:"已切換為簡體中文",day_to_night:"已切換為深色模式",night_to_day:"已切換為淺色模式",bgLight:"#49b1f5",bgDark:"#1f1f1f",position:"bottom-left"},infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js",buttonText:"載入更多"},isPhotoFigcaption:!1,islazyloadPlugin:!1,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"【Python 網路爬蟲筆記】BeautifulSoup Library - part 3",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="Yaoの程式小窩" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">載入中...</div></div></div><script>(()=>{const e=document.getElementById("loading-box"),d=document.body,t=()=>{e.classList.contains("loaded")||(d.style.overflow="",e.classList.add("loaded"))},o=()=>{d.style.overflow="hidden",e.classList.remove("loaded")};o(),"complete"===document.readyState?t():(window.addEventListener("load",t),document.addEventListener("DOMContentLoaded",t),setTimeout(t,7e3))})()</script><div id="web_bg" style="background-image:url(/img/web_background_smaller.jpg)"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">155</div></a><a href="/tags/"><div class="headline">標籤</div><div class="length-num">48</div></a><a href="/categories/"><div class="headline">分類</div><div class="length-num">19</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/python_cover.png)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/icon.png" alt="Logo"><span class="site-name">Yaoの程式小窩</span></a><a class="nav-page-title" href="/"><span class="site-name">【Python 網路爬蟲筆記】BeautifulSoup Library - part 3</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span> 返回首頁</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜尋</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">【Python 網路爬蟲筆記】BeautifulSoup Library - part 3</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">發表於</span><time class="post-meta-date-created" datetime="2025-09-29T15:50:27.000Z" title="發表於 2025-09-29 23:50:27">2025-09-29</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新於</span><time class="post-meta-date-updated" datetime="2025-09-29T15:51:03.004Z" title="更新於 2025-09-29 23:51:03">2025-09-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/programming/">程式設計</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/programming/python/">Python</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">總字數:</span><span class="word-count">4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">閱讀時間:</span><span>16分鐘</span></span><span class="post-meta-separator">|</span><span data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">瀏覽量:</span><span class="waline-pageview-count" data-path="/posts/37c25d58"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">評論數:</span><a href="/posts/37c25d58#post-comment"><span class="waline-comment-count" data-path="/posts/37c25d58"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="【Python-網路爬蟲筆記】BeautifulSoup-Library-part-3"><a href="#【Python-網路爬蟲筆記】BeautifulSoup-Library-part-3" class="headerlink" title="【Python 網路爬蟲筆記】BeautifulSoup Library - part 3"></a>【Python 網路爬蟲筆記】BeautifulSoup Library - part 3</h1><p>感謝你點進本篇文章！！我是 LukeTseng，一個熱愛資訊的無名創作者，由於近期大學開設大數據分析程式設計這門課程，裡面談到了爬蟲概念，讓我激起一些興趣，因而製作本系列筆記。</p><p>聲明：本篇筆記僅供個人學習用途，斟酌參考。</p><p>另外本篇筆記使用 VSCode 環境進行編寫，部分模組（函式庫）需自行下載。</p><h2 id="安裝-BeautifulSoup-模組"><a href="#安裝-BeautifulSoup-模組" class="headerlink" title="安裝 BeautifulSoup 模組"></a>安裝 BeautifulSoup 模組</h2><p>若使用 google colab 或 anaconda 環境者無須安裝。</p><p>指令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install beautifulsoup4</span><br></pre></td></tr></table></figure><h2 id="引入-BeautifulSoup-模組"><a href="#引入-BeautifulSoup-模組" class="headerlink" title="引入 BeautifulSoup 模組"></a>引入 BeautifulSoup 模組</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from bs4 import BeautifulSoup</span><br></pre></td></tr></table></figure><h2 id="為什麼我們要用-BeautifulSoup？"><a href="#為什麼我們要用-BeautifulSoup？" class="headerlink" title="為什麼我們要用 BeautifulSoup？"></a>為什麼我們要用 BeautifulSoup？</h2><p>BeautifulSoup 的主要用途是解析 HTML 和 XML，將網頁內容轉換成結構化的樹狀格式供程式操作 。</p><p>網頁資料解析與擷取是 BeautifulSoup 最主要的用途。</p><p>在網路爬蟲的世界，無可或缺的除了 request 模組外，就是 BeautifulSoup，有了這個模組就可以進一步擷取、分析我們想要的資訊。</p><p>例如可以擷取個人部落格所有文章的總瀏覽量，可以做到的方式就是透過 sitemap 一個一個進文章，去抓取每個文章的瀏覽量資訊，最後加總起來。</p><h2 id="第一支-BeautifulSoup-程式"><a href="#第一支-BeautifulSoup-程式" class="headerlink" title="第一支 BeautifulSoup 程式"></a>第一支 BeautifulSoup 程式</h2><p>以我的部落格網站為例：<a href="https://luketsengtw.github.io/">https://luketsengtw.github.io/</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://luketsengtw.github.io/&#x27;</span></span><br><span class="line">html = requests.get(url)</span><br><span class="line">soup = BeautifulSoup(html.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.title)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;title&gt;Yaoの程式小窩 - 只想好好學程式&lt;/title&gt;</span><br></pre></td></tr></table></figure><p>如果想要去掉 <code>&lt;title&gt;&lt;/title&gt;</code> 標籤的話，可以加上 <code>.string</code> 方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://luketsengtw.github.io/&#x27;</span></span><br><span class="line">html = requests.get(url)</span><br><span class="line">soup = BeautifulSoup(html.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.title.string) <span class="comment"># 加上 .string</span></span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Yaoの程式小窩 - 只想好好學程式</span><br></pre></td></tr></table></figure><h2 id="解析器（Parser）"><a href="#解析器（Parser）" class="headerlink" title="解析器（Parser）"></a>解析器（Parser）</h2><p>解析器是 BeautifulSoup 第二個參數，用於將 html 原始碼轉換成標籤樹好讓程式去做一些操作。</p><p>Python 內建的網頁解析器是 <code>html.parser</code>，如果要使用其它解析器需要額外安裝。</p><p>常見的解析器就有 <code>lxml</code> 跟 <code>html5lib</code>。</p><p>要安裝它們的話可以輸入指令：<code>pip install lxml html5lib</code></p><p>以下表格可以幫各位快速閱覽這些解析器的能力：</p><div class="table-container"><table><thead><tr><th>解析器</th><th>速度</th><th>準確性</th><th>容錯能力</th></tr></thead><tbody><tr><td>html.parser</td><td>中</td><td>最差</td><td>最差</td></tr><tr><td>lxml</td><td>最快</td><td>高</td><td>高</td></tr><tr><td>html5lib</td><td>最慢</td><td>最高</td><td>最高</td></tr></tbody></table></div><p>通常會使用 lxml 作為解析器，若在學習階段，不想裝這些有的沒的話，用後續用 html.parser 就可以了。</p><h2 id="BeautifulSoup-常用方法"><a href="#BeautifulSoup-常用方法" class="headerlink" title="BeautifulSoup 常用方法"></a>BeautifulSoup 常用方法</h2><h3 id="搜尋方法"><a href="#搜尋方法" class="headerlink" title="搜尋方法"></a>搜尋方法</h3><p><code>find()</code>、<code>find_all()</code> 是在 BeautifulSoup 中使用頻率最高的方法，因此先特別介紹這個。</p><p>基本上他的功能就是尋找這樣，<code>find()</code> 若有多個標籤存在的話，只會找第一個。</p><p>以下是一個範例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;html&gt;</span></span><br><span class="line"><span class="string">  &lt;body&gt;</span></span><br><span class="line"><span class="string">    &lt;div class=&quot;container&quot;&gt;</span></span><br><span class="line"><span class="string">      &lt;h2&gt;標題&lt;/h2&gt;</span></span><br><span class="line"><span class="string">      &lt;p class=&quot;content&quot;&gt;第一段內容&lt;/p&gt;</span></span><br><span class="line"><span class="string">      &lt;p class=&quot;content&quot;&gt;第二段內容&lt;/p&gt;</span></span><br><span class="line"><span class="string">      &lt;a href=&quot;https://example.com&quot;&gt;連結一&lt;/a&gt;</span></span><br><span class="line"><span class="string">      &lt;a href=&quot;https://google.com&quot;&gt;連結二&lt;/a&gt;</span></span><br><span class="line"><span class="string">    &lt;/div&gt;</span></span><br><span class="line"><span class="string">  &lt;/body&gt;</span></span><br><span class="line"><span class="string">&lt;/html&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找於 class_ = &#x27;content&#x27; 中第一個段落 &lt;p&gt; 元素</span></span><br><span class="line">first_p = soup.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;content&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(first_p.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找於 class_ = &#x27;content&#x27; 中所有段落 &lt;p&gt; 的元素</span></span><br><span class="line">all_p = soup.find_all(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;content&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> all_p:</span><br><span class="line">    <span class="built_in">print</span>(p.text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 html 所有內容中找所有連結 &lt;a&gt;</span></span><br><span class="line">links = soup.find_all(<span class="string">&#x27;a&#x27;</span>, href=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;連結文字: <span class="subst">&#123;link.text&#125;</span>, 網址: <span class="subst">&#123;link[<span class="string">&#x27;href&#x27;</span>]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">第一段內容</span><br><span class="line">第一段內容</span><br><span class="line">第二段內容</span><br><span class="line">連結文字: 連結一, 網址: https://example.com</span><br><span class="line">連結文字: 連結二, 網址: https://google.com</span><br></pre></td></tr></table></figure><h3 id="CSS-Selector"><a href="#CSS-Selector" class="headerlink" title="CSS Selector"></a>CSS Selector</h3><p>使用 <code>select()</code>。</p><p>以下是測試資料：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html_content = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="string">&lt;html&gt;</span></span><br><span class="line"><span class="string">&lt;head&gt;</span></span><br><span class="line"><span class="string">    &lt;title&gt;CSS 選擇器練習範例&lt;/title&gt;</span></span><br><span class="line"><span class="string">&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">    &lt;header id=&quot;main-header&quot; class=&quot;site-header&quot;&gt;</span></span><br><span class="line"><span class="string">        &lt;h1 class=&quot;title&quot;&gt;網站標題&lt;/h1&gt;</span></span><br><span class="line"><span class="string">        &lt;nav class=&quot;navigation&quot;&gt;</span></span><br><span class="line"><span class="string">            &lt;a href=&quot;/home&quot; class=&quot;nav-link active&quot;&gt;首頁&lt;/a&gt;</span></span><br><span class="line"><span class="string">            &lt;a href=&quot;/about&quot; class=&quot;nav-link&quot;&gt;關於我們&lt;/a&gt;</span></span><br><span class="line"><span class="string">            &lt;a href=&quot;/contact&quot; class=&quot;nav-link&quot;&gt;聯絡我們&lt;/a&gt;</span></span><br><span class="line"><span class="string">        &lt;/nav&gt;</span></span><br><span class="line"><span class="string">    &lt;/header&gt;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &lt;main class=&quot;container&quot;&gt;</span></span><br><span class="line"><span class="string">        &lt;article id=&quot;article-1&quot; class=&quot;post featured&quot;&gt;</span></span><br><span class="line"><span class="string">            &lt;h2 class=&quot;post-title&quot;&gt;第一篇文章&lt;/h2&gt;</span></span><br><span class="line"><span class="string">            &lt;p class=&quot;post-content&quot;&gt;這是第一篇文章的內容。&lt;/p&gt;</span></span><br><span class="line"><span class="string">            &lt;div class=&quot;meta&quot;&gt;</span></span><br><span class="line"><span class="string">                &lt;span class=&quot;author&quot; data-name=&quot;A&quot;&gt;作者：A&lt;/span&gt;</span></span><br><span class="line"><span class="string">                &lt;span class=&quot;date&quot; data-published=&quot;2025-01-01&quot;&gt;日期：2025-01-01&lt;/span&gt;</span></span><br><span class="line"><span class="string">            &lt;/div&gt;</span></span><br><span class="line"><span class="string">        &lt;/article&gt;</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &lt;article id=&quot;article-2&quot; class=&quot;post&quot;&gt;</span></span><br><span class="line"><span class="string">            &lt;h2 class=&quot;post-title&quot;&gt;第二篇文章&lt;/h2&gt;</span></span><br><span class="line"><span class="string">            &lt;p class=&quot;post-content highlight&quot;&gt;這是第二篇文章的重點內容。&lt;/p&gt;</span></span><br><span class="line"><span class="string">            &lt;div class=&quot;meta&quot;&gt;</span></span><br><span class="line"><span class="string">                &lt;span class=&quot;author&quot; data-name=&quot;B&quot;&gt;作者：B&lt;/span&gt;</span></span><br><span class="line"><span class="string">                &lt;span class=&quot;date&quot; data-published=&quot;2025-01-02&quot;&gt;日期：2025-01-02&lt;/span&gt;</span></span><br><span class="line"><span class="string">            &lt;/div&gt;</span></span><br><span class="line"><span class="string">        &lt;/article&gt;</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        &lt;aside class=&quot;sidebar&quot;&gt;</span></span><br><span class="line"><span class="string">            &lt;div class=&quot;widget recent-posts&quot;&gt;</span></span><br><span class="line"><span class="string">                &lt;h3&gt;最新文章&lt;/h3&gt;</span></span><br><span class="line"><span class="string">                &lt;ul&gt;</span></span><br><span class="line"><span class="string">                    &lt;li&gt;&lt;a href=&quot;/post1&quot;&gt;文章一&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                    &lt;li&gt;&lt;a href=&quot;/post2&quot;&gt;文章二&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                    &lt;li&gt;&lt;a href=&quot;/post3&quot;&gt;文章三&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">                &lt;/ul&gt;</span></span><br><span class="line"><span class="string">            &lt;/div&gt;</span></span><br><span class="line"><span class="string">        &lt;/aside&gt;</span></span><br><span class="line"><span class="string">    &lt;/main&gt;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &lt;footer id=&quot;main-footer&quot; class=&quot;site-footer&quot;&gt;</span></span><br><span class="line"><span class="string">        &lt;p&gt;&amp;copy; 2025 練習網站&lt;/p&gt;</span></span><br><span class="line"><span class="string">    &lt;/footer&gt;</span></span><br><span class="line"><span class="string">&lt;/body&gt;</span></span><br><span class="line"><span class="string">&lt;/html&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html_content, <span class="string">&#x27;lxml&#x27;</span>)</span><br></pre></td></tr></table></figure><p><strong>標籤選擇器</strong>：以下範例可選取 HTML 中所有的 h2 標籤及 p 段落標籤。</p><p>註：使用選擇器回傳的物件會是一個 list，所以以下的 <code>for h2 in h2_tags:</code> 會迭代 list 物件內的元素。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 選取所有 h2 標籤</span></span><br><span class="line">h2_tags = soup.select(<span class="string">&#x27;h2&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;所有 h2 標籤:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> h2 <span class="keyword">in</span> h2_tags:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  <span class="subst">&#123;h2.text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 選取所有段落</span></span><br><span class="line">paragraphs = soup.select(<span class="string">&#x27;p&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n找到 <span class="subst">&#123;<span class="built_in">len</span>(paragraphs)&#125;</span> 個段落&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">所有 h2 標籤:</span><br><span class="line">  第一篇文章</span><br><span class="line">  第二篇文章</span><br><span class="line"></span><br><span class="line">找到 3 個段落</span><br></pre></td></tr></table></figure><p><strong>ID 選擇器</strong>：<code>&lt;header id=&quot;main-header&quot; class=&quot;site-header&quot;&gt;</code> 做舉例，可以選擇 <code>&lt;header&gt;</code> 標籤裡面的 id。</p><p>要選取特定 ID，則使用一個 <code>#</code> 井字號作為前綴。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 選取特定 ID 的元素</span></span><br><span class="line">header = soup.select(<span class="string">&#x27;#main-header&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n標頭內容: <span class="subst">&#123;header[<span class="number">0</span>].find(<span class="string">&#x27;h1&#x27;</span>).text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 選取特定文章 ID</span></span><br><span class="line">article1 = soup.select(<span class="string">&#x27;#article-1&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;第一篇文章標題: <span class="subst">&#123;article1[<span class="number">0</span>].find(<span class="string">&#x27;h2&#x27;</span>).text&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">標頭內容: 網站標題</span><br><span class="line">第一篇文章標題: 第一篇文章</span><br></pre></td></tr></table></figure><p><strong>Class 選擇器</strong>：顧名思義，選擇 class 的值。</p><p>那 class 選擇器與 ID 選擇器不一樣，class 選擇器使用 <code>.</code> 一個半形點作為前綴。</p><p>註：以下程式碼的 <code>.get(&#39;href&#39;)</code> 是 BeautifulSoup 的方法，用於取得某個標籤的屬性值。</p><p>要取得屬性值也可直接寫 <code>link[&#39;href&#39;]</code>，與使用方法的差別在於這種方式比較不安全（會直接報錯），而 <code>.get()</code> 找不到的話會直接回傳 None。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 選取所有有 post 類別的元素</span></span><br><span class="line">posts = soup.select(<span class="string">&#x27;.post&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n找到 <span class="subst">&#123;<span class="built_in">len</span>(posts)&#125;</span> 篇文章:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> post <span class="keyword">in</span> posts:</span><br><span class="line">    title = post.find(<span class="string">&#x27;h2&#x27;</span>).text</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  <span class="subst">&#123;title&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 選取導航連結</span></span><br><span class="line">nav_links = soup.select(<span class="string">&#x27;.nav-link&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n找到 <span class="subst">&#123;<span class="built_in">len</span>(nav_links)&#125;</span> 個導航連結:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> nav_links:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  <span class="subst">&#123;link.text&#125;</span> -&gt; <span class="subst">&#123;link.get(<span class="string">&#x27;href&#x27;</span>)&#125;</span>&quot;</span>) <span class="comment"># get 方法取得屬性值</span></span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">找到 2 篇文章:</span><br><span class="line">  第一篇文章</span><br><span class="line">  第二篇文章</span><br><span class="line"></span><br><span class="line">找到 3 個導航連結:</span><br><span class="line">  首頁 -&gt; /home</span><br><span class="line">  關於我們 -&gt; /about</span><br><span class="line">  聯絡我們 -&gt; /contact</span><br></pre></td></tr></table></figure><p><strong>多重選擇器</strong>：可以同時選擇多個選擇器。像是可以同時有兩個類別，請見範例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 標籤 + 類別選擇器</span></span><br><span class="line">post_titles = soup.select(<span class="string">&#x27;h2.post-title&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n文章標題:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> post_titles:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  <span class="subst">&#123;title.text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多個類別選擇器（同時擁有兩個類別）</span></span><br><span class="line">featured_posts = soup.select(<span class="string">&#x27;.post.featured&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n精選文章數量: <span class="subst">&#123;<span class="built_in">len</span>(featured_posts)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">文章標題:</span><br><span class="line">  第一篇文章</span><br><span class="line">  第二篇文章</span><br><span class="line"></span><br><span class="line">精選文章數量: 1</span><br></pre></td></tr></table></figure><p><strong>後代選擇器</strong>：可以選擇一個標籤底下的其中一個標籤，假設要找 <code>&lt;article&gt;</code> 裡面的 <code>&lt;p&gt;</code>，那透過這個選擇器，就會找出 <code>&lt;article&gt;</code> 裡面的所有 <code>&lt;p&gt;</code> 標籤。</p><p>若要做到這個選擇器的功能，則在兩個標籤之間空一格。</p><p>以下是個範例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 選取 main 內的所有 span 標籤</span></span><br><span class="line">meta_spans = soup.select(<span class="string">&#x27;main span&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n文章元資訊:&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> span <span class="keyword">in</span> meta_spans:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  <span class="subst">&#123;span.text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 選取 article 內的 p 標籤</span></span><br><span class="line">article_paragraphs = soup.select(<span class="string">&#x27;article p&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n文章段落數: <span class="subst">&#123;<span class="built_in">len</span>(article_paragraphs)&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">文章元資訊:</span><br><span class="line">  作者：A</span><br><span class="line">  日期：2025-01-01</span><br><span class="line">  作者：B</span><br><span class="line">  日期：2025-01-02</span><br><span class="line"></span><br><span class="line">文章段落數: 2</span><br></pre></td></tr></table></figure><h2 id="透過-BeautifulSoup-提取純文字"><a href="#透過-BeautifulSoup-提取純文字" class="headerlink" title="透過 BeautifulSoup 提取純文字"></a>透過 BeautifulSoup 提取純文字</h2><p>透過 <code>.get_text()</code> 可獲取標籤內的內容，而非標籤本身（如<code>&lt;p&gt;123&lt;/p&gt;</code>）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;div class=&quot;article&quot;&gt;</span></span><br><span class="line"><span class="string">    &lt;h1&gt;文章標題&lt;/h1&gt;</span></span><br><span class="line"><span class="string">    &lt;p&gt;這是第一段落。&lt;/p&gt;</span></span><br><span class="line"><span class="string">    &lt;p&gt;這是&lt;strong&gt;重要&lt;/strong&gt;的第二段落。&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">soup = BeautifulSoup(html, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取純文字（包含所有子元素的文字）</span></span><br><span class="line">article = soup.find(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;article&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(article.get_text())</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">文章標題</span><br><span class="line">這是第一段落。</span><br><span class="line">這是重要的第二段落。</span><br></pre></td></tr></table></figure><h2 id="BeautifulSoup-結合-Requests-小應用"><a href="#BeautifulSoup-結合-Requests-小應用" class="headerlink" title="BeautifulSoup 結合 Requests 小應用"></a>BeautifulSoup 結合 Requests 小應用</h2><p>爬取網站：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.nptu.edu.tw/p/412-1000-2972.php?Lang=zh-tw">https://www.nptu.edu.tw/p/412-1000-2972.php?Lang=zh-tw</a></p><p>爬取國立屏東大學中的所有學術單位，含學院、以及旗下學系。</p><p>註：此爬蟲程式僅供學習用途，絕無任何其餘用途。</p><p>建議使用 colab 或 jupyter notebook 進行實作，若使用真實環境有可能會遇到 SSL Certificate 的問題。</p><p>另外可於該網站中任意處右鍵、按下檢查，開啟開發者工具介面，在左上方箭頭處可選取任意元素，選取完後會跳至該行的 HTML 原始碼。</p><p><img src="https://hackmd.io/_uploads/rJU4rmOngl.png" alt="image"></p><p><img src="https://hackmd.io/_uploads/BJySH7d2lg.png" alt="image"></p><p><img src="https://hackmd.io/_uploads/r1_HBXunlx.png" alt="image"></p><p>範例程式碼：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.nptu.edu.tw/p/412-1000-2972.php?Lang=zh-tw&quot;</span> <span class="comment"># 目標網址</span></span><br><span class="line">html = requests.get(url) <span class="comment"># 對目標網址發送 GET 請求</span></span><br><span class="line">html.encoding = <span class="string">&quot;utf-8&quot;</span> <span class="comment"># 設定正確編碼</span></span><br><span class="line">soup = BeautifulSoup(html.text, <span class="string">&quot;lxml&quot;</span>) <span class="comment"># 建立 BeautifulSoup 物件, 使用 lxml 解析器</span></span><br><span class="line"></span><br><span class="line">main_content = soup.find(<span class="string">&quot;div&quot;</span>, class_=<span class="string">&quot;main&quot;</span>) <span class="comment"># 主內容, </span></span><br><span class="line"><span class="keyword">if</span> main_content:</span><br><span class="line">    <span class="comment"># 獲取所有文字內容並按行分割</span></span><br><span class="line">    full_text = main_content.get_text()</span><br><span class="line">    lines = [line.strip() <span class="keyword">for</span> line <span class="keyword">in</span> full_text.split(<span class="string">&#x27;\n&#x27;</span>) <span class="keyword">if</span> line.strip()]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到學術單位列表的開始位置</span></span><br><span class="line">    start_idx = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> i, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(lines):</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;學術單位列表&quot;</span> <span class="keyword">in</span> line:</span><br><span class="line">            start_idx = i</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> start_idx != -<span class="number">1</span>:</span><br><span class="line">        relevant_lines = lines[start_idx+<span class="number">1</span>:]  <span class="comment"># 跳過&quot;學術單位列表&quot;這行</span></span><br><span class="line">        </span><br><span class="line">        current_college = <span class="literal">None</span></span><br><span class="line">        departments = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> relevant_lines:</span><br><span class="line">            <span class="comment"># 如果遇到包含&quot;學院&quot;的行，這是新的學院</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&quot;學院&quot;</span> <span class="keyword">in</span> line <span class="keyword">and</span> <span class="keyword">not</span> line.endswith(<span class="string">&quot;系&quot;</span>):</span><br><span class="line">                <span class="comment"># 如果之前已經有學院資料，先印出來</span></span><br><span class="line">                <span class="keyword">if</span> current_college <span class="keyword">and</span> departments:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;current_college&#125;</span>:&quot;</span>)</span><br><span class="line">                    <span class="keyword">for</span> dept <span class="keyword">in</span> departments:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">f&quot;  - <span class="subst">&#123;dept&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="built_in">print</span>()  <span class="comment"># 空行分隔</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 開始新的學院</span></span><br><span class="line">                current_college = line</span><br><span class="line">                departments = []</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果包含&quot;學系&quot;、&quot;研究所&quot;、&quot;中心&quot;或&quot;學程&quot;，這是學系</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">any</span>(keyword <span class="keyword">in</span> line <span class="keyword">for</span> keyword <span class="keyword">in</span> [<span class="string">&quot;學系&quot;</span>, <span class="string">&quot;研究所&quot;</span>, <span class="string">&quot;中心&quot;</span>, <span class="string">&quot;學程&quot;</span>]):</span><br><span class="line">                <span class="keyword">if</span> current_college:  <span class="comment"># 確保目前有學院</span></span><br><span class="line">                    departments.append(line)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 如果遇到校區資訊，結束處理</span></span><br><span class="line">            <span class="keyword">elif</span> <span class="string">&quot;校區&quot;</span> <span class="keyword">in</span> line:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 處理最後一個學院</span></span><br><span class="line">        <span class="keyword">if</span> current_college <span class="keyword">and</span> departments:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;current_college&#125;</span>:&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> dept <span class="keyword">in</span> departments:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;  - <span class="subst">&#123;dept&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>Output：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">管理學院:</span><br><span class="line">  - 商業大數據學系(含碩士班)</span><br><span class="line">  - 行銷與流通管理學系(含碩士班)</span><br><span class="line">  - 休閒事業經營學系(含碩士班)</span><br><span class="line">  - 不動產經營學系(含碩士班)</span><br><span class="line">  - 企業管理學系(含碩士班)</span><br><span class="line">  - 國際經營與貿易學系(含碩士班)</span><br><span class="line">  - 財務金融學系(含碩士班)</span><br><span class="line">  - 會計學系</span><br><span class="line">  - 大數據商務應用學士學位學程(113學年停招)</span><br><span class="line"></span><br><span class="line">資訊學院:</span><br><span class="line">  - 電腦與通訊學系</span><br><span class="line">  - 資訊工程學系(含碩士班)</span><br><span class="line">  - 電腦科學與人工智慧學系(含碩士班)</span><br><span class="line">  - 資訊管理學系(含碩士班)</span><br><span class="line">  - 智慧機器人學系</span><br><span class="line">  - 國際資訊科技與應用碩士學位學程</span><br><span class="line"></span><br><span class="line">教育學院:</span><br><span class="line">  - 教育行政研究所(含博碩士班)</span><br><span class="line">  - 教育心理與輔導學系(含碩士班)</span><br><span class="line">  - 教育學系(含碩士班)</span><br><span class="line">  - 特殊教育學系(含碩士班)</span><br><span class="line">  - 幼兒教育學系(含碩士班)</span><br><span class="line">  - STEM教育國際碩士學位學程</span><br><span class="line">  - 特殊教育中心</span><br><span class="line">  - 社區諮商中心</span><br><span class="line">  - 文教事業經營碩士在職學位學程(110學年停招)</span><br><span class="line"></span><br><span class="line">人文社會學院:</span><br><span class="line">  - 視覺藝術學系(含碩士班)</span><br><span class="line">  - 音樂學系(含碩士班)</span><br><span class="line">  - 文化創意產業學系(含碩士班)</span><br><span class="line">  - 社會發展學系(含碩士班)</span><br><span class="line">  - 中國語文學系(含碩士班)</span><br><span class="line">  - 應用日語學系</span><br><span class="line">  - 應用英語學系</span><br><span class="line">  - 英語學系(含碩士班)</span><br><span class="line">  - 文化發展學士學位學程原住民專班</span><br><span class="line">  - 文化事業發展碩士學位學程原住民專班</span><br><span class="line">  - 客家文化產業碩士學位學程</span><br><span class="line">  - 客家研究中心</span><br><span class="line">  - 原住民族教育研究中心</span><br><span class="line">  - 藝文中心</span><br><span class="line"></span><br><span class="line">理學院:</span><br><span class="line">  - 科學傳播學系(含科學傳播暨教育碩士班)</span><br><span class="line">  - 應用化學系(含碩士班)</span><br><span class="line">  - 應用數學系(含碩士班)</span><br><span class="line">  - 體育學系(含碩士班)</span><br><span class="line"></span><br><span class="line">國際學院:</span><br><span class="line">  - 東南亞發展中心</span><br><span class="line">  - 華語教學中心</span><br><span class="line"></span><br><span class="line">大武山學院:</span><br><span class="line">  - 共同教育中心</span><br><span class="line">  - 博雅教育中心</span><br><span class="line">  - 跨領域學程中心</span><br><span class="line">  - EMI發展中心</span><br><span class="line">  - 大武山社會實踐暨永續發展中心</span><br><span class="line">  - 新媒體創意應用碩士學位學程</span><br><span class="line">  - 大武山跨領域學士學位學程</span><br><span class="line">  - 師資培育中心</span><br><span class="line">  - 師資培育中心</span><br><span class="line">  - 教育學程組</span><br></pre></td></tr></table></figure><h2 id="總結"><a href="#總結" class="headerlink" title="總結"></a>總結</h2><p>BeautifulSoup 是 Python 中用於解析 HTML 和 XML 的函式庫，將網頁內容轉換成樹狀結構供程式操作。主要應用於網路爬蟲和網頁資料擷取。</p><h3 id="第一支-BeautifulSoup-範例"><a href="#第一支-BeautifulSoup-範例" class="headerlink" title="第一支 BeautifulSoup 範例"></a>第一支 BeautifulSoup 範例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://luketsengtw.github.io/&#x27;</span></span><br><span class="line">html = requests.get(url)</span><br><span class="line">soup = BeautifulSoup(html.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(soup.title)</span><br></pre></td></tr></table></figure><p><code>from bs4 import BeautifulSoup</code> 以此來引入 BeautifulSoup 做網頁分析與資料擷取。</p><p><code>soup = BeautifulSoup(html.text, &#39;html.parser&#39;)</code> 是建立 BeautifulSoup 的方法。</p><h3 id="解析器介紹"><a href="#解析器介紹" class="headerlink" title="解析器介紹"></a>解析器介紹</h3><div class="table-container"><table><thead><tr><th>解析器</th><th>速度</th><th>準確性</th><th>容錯能力</th></tr></thead><tbody><tr><td>html.parser</td><td>中</td><td>最差</td><td>最差</td></tr><tr><td>lxml</td><td>最快</td><td>高</td><td>高</td></tr><tr><td>html5lib</td><td>最慢</td><td>最高</td><td>最高</td></tr></tbody></table></div><h3 id="BeautifulSoup-的常用方法"><a href="#BeautifulSoup-的常用方法" class="headerlink" title="BeautifulSoup 的常用方法"></a>BeautifulSoup 的常用方法</h3><ul><li>find() - 找第一個符合的元素</li><li>find_all() - 找所有符合的元素</li></ul><p>以下程式碼分別找出第一個 <code>&lt;p&gt;</code> 和找出所有的 <code>&lt;p&gt;</code> 標籤。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">first_p = soup.find(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;content&#x27;</span>)</span><br><span class="line">all_p = soup.find_all(<span class="string">&#x27;p&#x27;</span>, class_=<span class="string">&#x27;content&#x27;</span>)</span><br></pre></td></tr></table></figure><h4 id="CSS-選擇器"><a href="#CSS-選擇器" class="headerlink" title="CSS 選擇器"></a>CSS 選擇器</h4><p>使用 <code>select()</code> 方法：</p><ul><li>一般標籤：<code>soup.select(&#39;h2&#39;)</code></li><li>ID 選擇器（用 <code>#</code>）：<code>soup.select(&#39;#main-header&#39;)</code></li><li>Class 選擇器（用 <code>.</code>）：<code>soup.select(&#39;.nav-link&#39;)</code></li><li>多重選擇器：<code>soup.select(&#39;h2.post-title&#39;)</code></li><li>後代選擇器（空格）：<code>soup.select(&#39;main span&#39;)</code></li></ul><h4 id="文字提取"><a href="#文字提取" class="headerlink" title="文字提取"></a>文字提取</h4><ul><li><code>soup.title.string</code> - 取得標籤內文字</li><li><code>element.get_text()</code> - 取得純文字內容（去除標籤）</li><li><code>link[&#39;href&#39;] 或 link.get(&#39;href&#39;)</code> - 取得屬性值</li></ul><h3 id="基本爬蟲模板"><a href="#基本爬蟲模板" class="headerlink" title="基本爬蟲模板"></a>基本爬蟲模板</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;目標網址&quot;</span></span><br><span class="line">html = requests.get(url)</span><br><span class="line">html.encoding = <span class="string">&quot;utf-8&quot;</span>  <span class="comment"># 設定編碼</span></span><br><span class="line">soup = BeautifulSoup(html.text, <span class="string">&quot;lxml&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 找到主要內容區域</span></span><br><span class="line">main_content = soup.find(<span class="string">&quot;div&quot;</span>, class_=<span class="string">&quot;main&quot;</span>)</span><br><span class="line">text = main_content.get_text()</span><br></pre></td></tr></table></figure><h2 id="參考資料"><a href="#參考資料" class="headerlink" title="參考資料"></a>參考資料</h2><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://steam.oxxostudio.tw/category/python/spider/beautiful-soup.html">Beautiful Soup 函式庫 - Python 網路爬蟲教學 | STEAM 教育學習網</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup Documentation — Beautiful Soup 4.13.0 documentation</a></p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.geeksforgeeks.org/python/implementing-web-scraping-python-beautiful-soup/">Implementing Web Scraping in Python with BeautifulSoup - GeeksforGeeks</a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://luketsengtw.github.io">LukeTseng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章連結: </span><span class="post-copyright-info"><a href="https://luketsengtw.github.io/posts/37c25d58">https://luketsengtw.github.io/posts/37c25d58</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版權聲明: </span><span class="post-copyright-info">本部落格所有文章除特別聲明外，均採用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 授權協議。轉載請註明來源 <a href="https://luketsengtw.github.io" target="_blank">Yaoの程式小窩</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/%E7%A8%8B%E5%BC%8F%E8%A8%AD%E8%A8%88/">程式設計</a><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E7%B6%B2%E9%A0%81/">網頁</a><a class="post-meta__tags" href="/tags/%E7%B6%B2%E9%A0%81%E7%A8%8B%E5%BC%8F%E8%A8%AD%E8%A8%88/">網頁程式設計</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%9F%B2/">爬蟲</a><a class="post-meta__tags" href="/tags/web-crawler/">web crawler</a></div><div class="post-share"><div class="social-share" data-image="/img/python_cover.png" data-sites="facebook, twitter"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/da4a043f" title="如何解決 VMWare AMD V / RVI 不支援該平台問題"><img class="cover" src="/img/vmware_icon.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">如何解決 VMWare AMD V / RVI 不支援該平台問題</div></div><div class="info-2"><div class="info-item-1">如何解決 VMWare AMD V / RVI 不支援該平台問題大家好，我是 LukeTseng，近期將桌機轉到筆電時，在筆電安裝 VMWare，啟動虛擬機時遇到了一些問題，因此撰寫本篇文章來解決這個問題。 那麼這個問題就是，開啟虛擬機後，會跳出： Virtualized AMD-V/RVI is not supported on this platform.Continue without virtualized AMD-V/RVI? 這問題是因為 Windows 11 預設啟用 Virtualization-based Security（VBS），這個功能使用 Hyper-V 作為底層技術，會佔用硬體虛擬化資源，導致 VMware Workstation 無法使用 AMD-V/RVI 進行虛擬化。 然後接下來就讓我來一步一步告訴各位怎麼做吧。 第一步：關閉【記憶體完整性】首先對 Windows Defender 的 tray icon 按下滑鼠左鍵一下。 進入介面後，在左側邊欄選擇【裝置安全性】。 再來於【核心隔離】的下方點擊【核心隔離詳細資料】。 然後確保【記憶體...</div></div></div></a><a class="pagination-related" href="/posts/b4e9bcb2" title="【VSCode &amp; Ubuntu】超詳細教學！如何在 VSCode 遠端控制 VMWare Terminal"><img class="cover" src="/img/vmware_icon.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">【VSCode & Ubuntu】超詳細教學！如何在 VSCode 遠端控制 VMWare Terminal</div></div><div class="info-2"><div class="info-item-1">【VSCode &amp; Ubuntu】超詳細教學！如何在 VSCode 遠端控制 VMWare Terminal大家好我是 LukeTseng，會想撰寫本次文章主要是因為在虛擬機與 Windows 之間切換複製貼上、打指令太麻煩了，而且 Ubuntu 的 vim 編輯器用的不是那麼習慣XD，所以特此製作本篇文章介紹如何在 VSCode 透過 SSH 遠端控制 VMWare Ubuntu 的 Terminal。 若本篇文章部分指令或敘述有誤，麻煩各位敬請勘誤，感謝你的閱讀。 若還沒安裝過 VSCode 的可以前往該連結下載：https://code.visualstudio.com/ VSCode Extension : Remote - SSH在左側欄位找到一個有四個方塊圖案的，點下去後，來到我們的擴充商店，搜尋 Remote 即可找到 【Remote - SSH】插件。 註：這邊我已經安裝過了，所以會出現 Uninstall 的字樣。 虛擬機設定開啟我們的虛擬機，開啟【Edit virtual machine settings】： 找到 【Network Adapter...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相關推薦</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/15752481" title="【Python 網路爬蟲筆記】Requests Library - part 2"><img class="cover" src="/img/python_cover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-21</div><div class="info-item-2">【Python 網路爬蟲筆記】Requests Library - part 2</div></div><div class="info-2"><div class="info-item-1">【Python 網路爬蟲筆記】Requests Library - part 2感謝你點進本篇文章！！我是 LukeTseng，一個熱愛資訊的無名創作者，由於近期大學開設大數據分析程式設計這門課程，裡面談到了爬蟲概念，讓我激起一些興趣，因而製作本系列筆記。 聲明：本篇筆記僅供個人學習用途，斟酌參考。 另外本篇筆記使用 VSCode 環境進行編寫，部分模組（函式庫）需自行下載。 安裝 Requests 函式庫Colab 及 Anaconda 環境無須安裝，內建即有。 若不確定自己有裝的話，可以輸入 pip list 查看已安裝的所有模組。 使用指令 pip install requests。 像我已經安裝過了，再安裝一次他會跟你說 Requirement already satisfied，表示你裝過了。 另外一個測試有沒有安裝過該模組的方法，可以打開 VSCode 或其他環境，輸入以下指令並執行即可： 12import requestsprint(requests.__version__) 執行後會在最下面出現版本資訊。 Requests 基礎用法使用前須引入模組 impo...</div></div></div></a><a class="pagination-related" href="/posts/54836959" title="【Python 網路爬蟲筆記】Introduction - part 1"><img class="cover" src="/img/python_cover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-15</div><div class="info-item-2">【Python 網路爬蟲筆記】Introduction - part 1</div></div><div class="info-2"><div class="info-item-1">【Python 網路爬蟲筆記】Introduction - part 1感謝你點進本篇文章！！我是 LukeTseng，一個熱愛資訊的無名創作者，由於近期大學開設大數據分析程式設計這門課程，裡面談到了爬蟲概念，讓我激起一些興趣，因而製作本系列筆記。 聲明：本篇筆記僅供個人學習用途，斟酌參考。 何謂網路爬蟲（Web Crawler）？ Image Source：https://www.freepik.com/free-vector/cute-spider-sticker-white-background_20770625.htm#fromView=keyword&amp;page=1&amp;position=48&amp;uuid=58458110-a248-4037-895d-b6b66f71a92b&amp;query=Spider+cartoon 網路爬蟲（Web Crawler），也叫網路蜘蛛，是一種用來自動瀏覽全球資訊網的網路機器人。其目的一般為編纂網路索引。From WikiPedia 網路爬蟲最主要的用處是可以「自動化」幫我們擷取及收集想要的資訊。 一般的 We...</div></div></div></a><a class="pagination-related" href="/posts/3e7fd447" title="【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4"><img class="cover" src="/img/python_cover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-17</div><div class="info-item-2">【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4</div></div><div class="info-2"><div class="info-item-1">【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4感謝你點進本篇文章！！我是 LukeTseng，一個熱愛資訊的無名創作者，由於近期大學開設大數據分析程式設計這門課程，裡面談到了爬蟲概念，讓我激起一些興趣，因而製作本系列筆記。 聲明：本篇筆記僅供個人學習用途，斟酌參考。 本篇筆記使用 Jupyter Notebook，搭載 Anaconda 虛擬環境，如需下載者可至該網址：https://www.anaconda.com/download 安裝 Selenium 模組透過以下指令： 1pip install selenium 在 Jupyter Notebook（安裝完後記得 Restart Kernel 才會啟用）： 1!pip install selenium 什麼是 Selenium？Selenium 是一種開源的網頁瀏覽器自動化工具，可以透過程式碼來模擬 user 在瀏覽器上的各種操作（像人一樣），從而完成自動化測試或網頁爬蟲任務。 Selenium 就是動態爬蟲中應用到最重要的技術。 Selenium 用 We...</div></div></div></a><a class="pagination-related" href="/posts/3e674b2a" title="【Python 筆記】正規運算式（Regular Expression）"><img class="cover" src="/img/python_cover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-12</div><div class="info-item-2">【Python 筆記】正規運算式（Regular Expression）</div></div><div class="info-2"><div class="info-item-1">【Python 筆記】正規運算式（Regular Expression）感謝您點進本篇文章，本篇文章為我 LukeTseng 個人首篇 Python 筆記系列文章，主要記錄我個人學習軌跡，所有內容皆用於個人學習用途，斟酌參考。若文章有任意處有誤，煩請各位指點，謝謝。 簡介這東西的名字很多，有什麼正規表達式、正規表示法、規則運算式、常規表示法等等，我個人比較習慣叫他是正規運算式，總之他的名字就是 Regular Expression（簡稱 RE、regex）就對了，在這之後我都叫他是 regex 縮寫。 regex 是一套用來描述和比對字串樣式規則的「語法」或「表示法」，通常被嵌入在各大程式語言當中，例如我們最愛用的 Python 就是其一。regex 在處理和解析字串方面十分強大，因此也是我們要學習的對象。 你可能想說在 notepad 裡面就可以用搜尋、取代這些功能了，為什麼還需要 regex？因為 regex 他不只是只有搜尋、取代這些功能而已，他還有篩選的功能，例如可以篩出特定字元、字串，以此來找到電子郵件格式及電話號碼。 在 Python 使用 regex1import ...</div></div></div></a><a class="pagination-related" href="/posts/e16215e4" title="【演算法筆記】計數排序 &#x2F; 桶排序 &#x2F; 基數排序"><img class="cover" src="/img/python_cover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2024-08-14</div><div class="info-item-2">【演算法筆記】計數排序 &#x2F; 桶排序 &#x2F; 基數排序</div></div><div class="info-2"><div class="info-item-1">【演算法筆記】計數排序 / 桶排序 / 基數排序大家好我是 LukeTseng！這篇是我的一個小小學習筆記，為了想要了解更快速的排序法，所以特別製作了此篇。 在總結部分會將這三種排序法的各個優缺點，以及其他屬性等等做比較。 總之廢話不多說，進入正題吧： 計數排序法（Counting Sort）計數排序法（Counting Sort）是一個有線性時間成長的排序法，相較於以往較為基礎的泡沫排序法（Bubble Sort）、插入排序法（Insertion Sort）（時間複雜度：O(n^2)）等，或是適用於大資料且排序速度較快的排序法：快速排序法（Quick Sort）、合併排序法（Merge Sort）（時間複雜度：O(n log n)），都還要來得快。 它的時間複雜度是 O(n)，如果要準確一點說的話，是 O(n+k)，k 是資料量。 適用情況在於資料量少的時候，有多少呢？資料量在幾千個以內，且資料範圍不超過幾百個（例如 1 到 100 或 1 到 500）的時候，計數排序法就仍有效率排序。 計數排序的演算步驟如下： 找出要排序的數列當中之最大值 初始化一個長度為 max+1 的...</div></div></div></a><a class="pagination-related" href="/posts/2bbc9929" title="【Python 資安筆記】編碼（Encoding）"><img class="cover" src="/img/hacking.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-09-20</div><div class="info-item-2">【Python 資安筆記】編碼（Encoding）</div></div><div class="info-2"><div class="info-item-1">【Python 資安筆記】編碼（Encoding）Cover : https://www.publicdomainpictures.net/en/view-image.php?image=563833&amp;picture=hacking 感謝你點進本篇筆記！該系列筆記主要紀錄學習資安的過程，以及我個人的一些簡單白話解釋，另外也涉及到在學校中上課所學的資安技巧及知識。 若本篇文章有誤，麻煩各位告訴我，這樣才能好讓我進步！謝謝～ 自網站 CryptoHack 進行學習：https://cryptohack.org/ ASCII 字元編碼Python 之間的轉換可以用 chr() 以及 ord() 兩個函式做到。 以下是對於 chr() 以及 ord() 兩函式的解釋： chr() 接受十進位或十六進位的數字，回傳值為傳入參數所對應的 ASCII 字元，如傳入參數 97，就回傳輸出 &#39;a&#39; 這個字元。 ord() 與 chr() 相反，它接受一個字元當作參數傳入，回傳對應的 ASCII 數值，或是 Unicode 數值。 以下程式碼就做了兩個函數之間的轉換關係：...</div></div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 評論</span></div></div><div class="comment-wrap"><div><div id="waline-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/avatar.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">LukeTseng</div><div class="author-info-description">一個軟硬體都愛的資訊人，也是個無名的程式熱愛者。目前仍主要活躍於 Hackmd 平台上，基本上本站與此同步更新。</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">155</div></a><a href="/tags/"><div class="headline">標籤</div><div class="length-num">48</div></a><a href="/categories/"><div class="headline">分類</div><div class="length-num">19</div></a></div><a id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/LukeTsengTW"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/LukeTsengTW" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github" style="color:#hdhfbb"></i></a><a class="social-icon" href="https://hackmd.io/@LukeTseng" rel="external nofollow noreferrer" target="_blank" title="Hackmd"><i class="fas fa-file-lines" style="color:#4e44fe"></i></a><a class="social-icon" href="https://www.instagram.com/moonouo_" rel="external nofollow noreferrer" target="_blank" title="Instagram"><i class="fab fa-square-instagram" style="color:#dd2a7b"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目錄</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E3%80%90Python-%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2%E7%AD%86%E8%A8%98%E3%80%91BeautifulSoup-Library-part-3"><span class="toc-number">1.</span> <span class="toc-text">【Python 網路爬蟲筆記】BeautifulSoup Library - part 3</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%9D-BeautifulSoup-%E6%A8%A1%E7%B5%84"><span class="toc-number">1.1.</span> <span class="toc-text">安裝 BeautifulSoup 模組</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E5%85%A5-BeautifulSoup-%E6%A8%A1%E7%B5%84"><span class="toc-number">1.2.</span> <span class="toc-text">引入 BeautifulSoup 模組</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%82%BA%E4%BB%80%E9%BA%BC%E6%88%91%E5%80%91%E8%A6%81%E7%94%A8-BeautifulSoup%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">為什麼我們要用 BeautifulSoup？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%94%AF-BeautifulSoup-%E7%A8%8B%E5%BC%8F"><span class="toc-number">1.4.</span> <span class="toc-text">第一支 BeautifulSoup 程式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90%E5%99%A8%EF%BC%88Parser%EF%BC%89"><span class="toc-number">1.5.</span> <span class="toc-text">解析器（Parser）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup-%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-number">1.6.</span> <span class="toc-text">BeautifulSoup 常用方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%90%9C%E5%B0%8B%E6%96%B9%E6%B3%95"><span class="toc-number">1.6.1.</span> <span class="toc-text">搜尋方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CSS-Selector"><span class="toc-number">1.6.2.</span> <span class="toc-text">CSS Selector</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%8F%E9%81%8E-BeautifulSoup-%E6%8F%90%E5%8F%96%E7%B4%94%E6%96%87%E5%AD%97"><span class="toc-number">1.7.</span> <span class="toc-text">透過 BeautifulSoup 提取純文字</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup-%E7%B5%90%E5%90%88-Requests-%E5%B0%8F%E6%87%89%E7%94%A8"><span class="toc-number">1.8.</span> <span class="toc-text">BeautifulSoup 結合 Requests 小應用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B8%BD%E7%B5%90"><span class="toc-number">1.9.</span> <span class="toc-text">總結</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%94%AF-BeautifulSoup-%E7%AF%84%E4%BE%8B"><span class="toc-number">1.9.1.</span> <span class="toc-text">第一支 BeautifulSoup 範例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90%E5%99%A8%E4%BB%8B%E7%B4%B9"><span class="toc-number">1.9.2.</span> <span class="toc-text">解析器介紹</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BeautifulSoup-%E7%9A%84%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-number">1.9.3.</span> <span class="toc-text">BeautifulSoup 的常用方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#CSS-%E9%81%B8%E6%93%87%E5%99%A8"><span class="toc-number">1.9.3.1.</span> <span class="toc-text">CSS 選擇器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%87%E5%AD%97%E6%8F%90%E5%8F%96"><span class="toc-number">1.9.3.2.</span> <span class="toc-text">文字提取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E7%88%AC%E8%9F%B2%E6%A8%A1%E6%9D%BF"><span class="toc-number">1.9.4.</span> <span class="toc-text">基本爬蟲模板</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%83%E8%80%83%E8%B3%87%E6%96%99"><span class="toc-number">1.10.</span> <span class="toc-text">參考資料</span></a></li></ol></li></ol></div></div><div class="card-widget card-post-series"><div class="item-headline"><i class="fa-solid fa-layer-group"></i><span>Python 爬蟲系列文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/3e7fd447" title="【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4"><img src="/img/python_cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4"></a><div class="content"><a class="title" href="/posts/3e7fd447" title="【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4">【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4</a><time datetime="2025-10-17T15:31:44.000Z" title="發表於 2025-10-17 23:31:44">2025-10-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/37c25d58" title="【Python 網路爬蟲筆記】BeautifulSoup Library - part 3"><img src="/img/python_cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Python 網路爬蟲筆記】BeautifulSoup Library - part 3"></a><div class="content"><a class="title" href="/posts/37c25d58" title="【Python 網路爬蟲筆記】BeautifulSoup Library - part 3">【Python 網路爬蟲筆記】BeautifulSoup Library - part 3</a><time datetime="2025-09-29T15:50:27.000Z" title="發表於 2025-09-29 23:50:27">2025-09-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/15752481" title="【Python 網路爬蟲筆記】Requests Library - part 2"><img src="/img/python_cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Python 網路爬蟲筆記】Requests Library - part 2"></a><div class="content"><a class="title" href="/posts/15752481" title="【Python 網路爬蟲筆記】Requests Library - part 2">【Python 網路爬蟲筆記】Requests Library - part 2</a><time datetime="2025-09-21T07:00:59.000Z" title="發表於 2025-09-21 15:00:59">2025-09-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/54836959" title="【Python 網路爬蟲筆記】Introduction - part 1"><img src="/img/python_cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Python 網路爬蟲筆記】Introduction - part 1"></a><div class="content"><a class="title" href="/posts/54836959" title="【Python 網路爬蟲筆記】Introduction - part 1">【Python 網路爬蟲筆記】Introduction - part 1</a><time datetime="2025-09-15T14:30:52.000Z" title="發表於 2025-09-15 22:30:52">2025-09-15</time></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/3e7fd447" title="【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4"><img src="/img/python_cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4"></a><div class="content"><a class="title" href="/posts/3e7fd447" title="【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4">【Python 網路爬蟲筆記】Selenium Library、爬取 Hackmd 文章專題 - part 4</a><time datetime="2025-10-17T15:31:44.000Z" title="發表於 2025-10-17 23:31:44">2025-10-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3ccc84f5" title="【Leetcode C++ 解題筆記】Stack - part 3"><img src="/img/leetcode_cover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Leetcode C++ 解題筆記】Stack - part 3"></a><div class="content"><a class="title" href="/posts/3ccc84f5" title="【Leetcode C++ 解題筆記】Stack - part 3">【Leetcode C++ 解題筆記】Stack - part 3</a><time datetime="2025-10-17T13:38:33.000Z" title="發表於 2025-10-17 21:38:33">2025-10-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/194969b8" title="【Uva 解題筆記】12149 - Feynman"><img src="/img/uva_cover.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Uva 解題筆記】12149 - Feynman"></a><div class="content"><a class="title" href="/posts/194969b8" title="【Uva 解題筆記】12149 - Feynman">【Uva 解題筆記】12149 - Feynman</a><time datetime="2025-10-16T09:15:32.000Z" title="發表於 2025-10-16 17:15:32">2025-10-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/b5f60bc8" title="【Uva 解題筆記】12015 - Google is Feeling Lucky"><img src="/img/uva_cover.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="【Uva 解題筆記】12015 - Google is Feeling Lucky"></a><div class="content"><a class="title" href="/posts/b5f60bc8" title="【Uva 解題筆記】12015 - Google is Feeling Lucky">【Uva 解題筆記】12015 - Google is Feeling Lucky</a><time datetime="2025-10-16T07:45:56.000Z" title="發表於 2025-10-16 15:45:56">2025-10-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/d93c9963" title="什麼是 Hamming Code（漢明碼）？"><img src="/img/Computer_Science_Word_Cloud.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="什麼是 Hamming Code（漢明碼）？"></a><div class="content"><a class="title" href="/posts/d93c9963" title="什麼是 Hamming Code（漢明碼）？">什麼是 Hamming Code（漢明碼）？</a><time datetime="2025-10-15T12:51:12.000Z" title="發表於 2025-10-15 20:51:12">2025-10-15</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(/img/python_cover.png)"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2024 - 2025 By LukeTseng</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主題 </span><a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="閱讀模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="繁簡轉換">繁</button><button id="darkmode" type="button" title="日夜模式切換"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="單欄和雙欄切換"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="設定"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目錄"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往評論"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到頂端"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><div class="js-pjax"><script>(()=>{const t=()=>{if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"none"},chtml:{scale:1.1},options:{enableMenu:!0,renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const n=!!e.type.match(/; *mode=display/),a=new t.options.MathItem(e.textContent,t.inputJax[0],n),d=document.createTextNode("");e.parentNode.replaceChild(d,e),a.start={node:d,delim:"",n:0},a.end={node:d,delim:"",n:0},t.math.push(a)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}};btf.addGlobalFn("encrypt",t,"mathjax"),window.pjax?t():window.addEventListener("load",t)})()</script><script>(()=>{let e=window.walineFn||null;const n="shuoshuo"===GLOBAL_CONFIG_SITE.pageType,t={lang:"zh-TW",locale:{seconds:"秒前",minutes:"分鐘前",hours:"小時前",days:"天前",now:"剛剛",gif:"表情包",gifSearchPlaceholder:"搜尋 gif 動圖",comment:"留言",placeholder:"歡迎留言，請務必友善發言，減少衝突，讓世界更美好～"},emoji:["https://unpkg.com/@waline/emojis@1.0.1/tw-emoji"]},i=(e,i=document,o=window.location.pathname)=>{const s=e({el:i.querySelector("#waline-wrap"),serverURL:"https://discussion-kohl.vercel.app/",pageview:!0,dark:'html[data-theme="dark"]',comment:!0,...t,path:n?o:t&&t.path||o});n&&(window.shuoshuoComment.destroyWaline=()=>{s.destroy(),i.children.length&&(i.innerHTML="",i.classList.add("no-comment"))})},o=(n,t)=>{e?i(e,n,t):btf.getCSS("https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.css").then(()=>import("https://cdn.jsdelivr.net/npm/@waline/client/dist/waline.min.js")).then(({init:o})=>{e=o||Waline.init,i(e,n,t),window.walineFn=e})};n?window.shuoshuoComment={loadComment:o}:setTimeout(o,0)})()</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜尋</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/lite/builds/browser.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script></div><noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5BKRW8SL" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript></div></body></html>